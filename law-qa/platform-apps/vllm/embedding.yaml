server:
  image:
    registry: "registry.cn-hangzhou.aliyuncs.com"
    repository: "t9k/vllm-openai"
    tag: "v0.10.1"
    pullPolicy: Always

  resources:
    limits:
      cpu: 1
      memory: 16Gi
      nvidia.com/gpu: 1

  model:
    deployName: "Qwen3-Embedding-0.6B"
    volume:
      storageClass: ""
      size: 32Gi
      accessModes:
        - ReadWriteOnce
      existingClaim: "law-qa"
      subPath: "Qwen3-Embedding-0.6B"

  autoScaling:
    minReplicas: 1
    maxReplicas: 1
    annotations: {}

  app:
    extraArgs:
      - "--gpu-memory-utilization=0.95"

  env:
    - name: "VLLM_USE_V1"
      value: "0"
  extraVolumeMounts: []
  extraVolume: []
  securityContext: {}
  nodeSelector: {}

initializer:
  image:
    registry: "$(T9K_APP_IMAGE_REGISTRY)"
    repository: "$(T9K_APP_IMAGE_NAMESPACE)/kubectl"
    tag: "1.27"
    pullPolicy: IfNotPresent
